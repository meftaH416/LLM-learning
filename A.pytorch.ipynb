{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b59e3da-bc34-4ffe-8989-bf4c575be433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0+cu124'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6658b87-bf69-4cff-bb6f-e0169612a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "\n",
    "# Ensure GPU or CPU intigration based on vaiability\n",
    "#-----------------------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ef167-0aef-48b0-924f-a71089e551ce",
   "metadata": {},
   "source": [
    "## Different way to multiply 1D or 2D Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef29981b-f4d7-4b86-b675-c4114c8928a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required to multiply two matrix is 0.021788358688354492 sec.\n"
     ]
    }
   ],
   "source": [
    "# For any Dimensional Vector-- Dot Product\n",
    "\n",
    "import time\n",
    "\n",
    "torch.manual_seed(123)\n",
    "start = time.time()\n",
    "x1 = torch.rand(100, 50)\n",
    "x2 = torch.rand(50, 50)\n",
    "x1@x2.T\n",
    "end = time.time()\n",
    "print(f\"Time required to multiply two matrix is {end-start} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea7e65a6-fa6b-47f6-a948-66105f493a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required to multiply two matrix is 0.0003390312194824219 sec.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "torch.manual_seed(123)\n",
    "start = time.time()\n",
    "x1 = torch.rand(100,50)\n",
    "x2 = torch.rand(50,50)\n",
    "torch.matmul(x1, x2.T)\n",
    "end = time.time()\n",
    "print(f\"Time required to multiply two matrix is {end-start} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e7297d-e433-4aa8-bc50-16da91f01a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required to multiply two matrix is 0.0006654262542724609 sec.\n"
     ]
    }
   ],
   "source": [
    "# Only for 1D Vector-- Dot Product\n",
    "\n",
    "import time\n",
    "import random\n",
    "torch.manual_seed(123)\n",
    "start = time.time()\n",
    "x1 = torch.rand(50)\n",
    "\n",
    "torch.manual_seed(23)\n",
    "x2 = torch.rand(50)\n",
    "torch.dot(x1, x2)\n",
    "end = time.time()\n",
    "print(f\"Time required to multiply two matrix is {end-start} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15190e8f-3a68-4327-ba3e-07477935bebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The row shape of the vector/array:  4\n"
     ]
    }
   ],
   "source": [
    "# An array 1D\n",
    "y = torch.tensor([0, 1, 2, 2])\n",
    "print(\"The row shape of the vector/array: \",y.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f391698-11b7-4677-8f85-4559bc23ebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2]])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to an array of column num =1 and row autocalculated\n",
    "y_trans = y.view(-1,1)\n",
    "print(y_trans)\n",
    "print(y_trans.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7808d9f5-022b-43fb-9430-aebf5c944503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2]])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# make sure the values are long() or integer\n",
    "y_trans_long = y.view(-1,1).long()\n",
    "print(y_trans_long)\n",
    "print(y_trans_long.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed184848-e494-4f1b-9ca1-ad8a7802daad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# A zeros array 2D\n",
    "zeros_array = torch.zeros(y.size(0), 4)\n",
    "print(zeros_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "844fbf1c-fe84-4778-a37e-d246e498fef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 1.],\n",
       "        [1., 2., 1.],\n",
       "        [1., 1., 2.],\n",
       "        [1., 2., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It \"scatters\" along dimension 1 (columns) the value 2 at the indices given by tensor having \n",
    "# rows of zeros_array\n",
    "exm_tensor = torch.ones(4,3)\n",
    "exm_tensor.scatter_(1, torch.tensor([[1],[1],[2],[1]]), 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d1ff4f-c022-4e12-81d0-1538a55e85d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Apply same principle to zeros_array\n",
    "hot_encode = zeros_array.scatter_(1, y_trans_long, 1).float()\n",
    "print(hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbeaeda-25d6-4852-bf2f-4770de5b68bb",
   "metadata": {},
   "source": [
    "## Using the above concept let's build the function for one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81a46a66-942d-49be-8338-c86e77dda42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot encoding matrix is \n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# num_classes represnts how many class we want as output. These are the columns\n",
    "\n",
    "def one_hot_encoding(index_array, num_classes):\n",
    "    \n",
    "    # Reshaping the array to an array of column num =1 and row autocalculated\n",
    "    y = torch.tensor(index_array)\n",
    "    y_trans = y.view(-1,1)\n",
    "    # make sure the values are long() or integer\n",
    "    y_trans_long = y.view(-1,1).long()\n",
    "\n",
    "    # An 2D zeros array having rows= rows of index_array and columns = num_classes\n",
    "    zeros_array = torch.zeros(y.size(0), num_classes)\n",
    "\n",
    "    #It \"scatters\" along dimension 1 (columns) the value 2 at the indices given by tensor having \n",
    "    # rows of zeros_array. Applied to tensors\n",
    "    hot_encode = zeros_array.scatter_(1, y_trans_long, 1).float()\n",
    "    \n",
    "    return hot_encode\n",
    "    \n",
    "y = [0, 1, 2, 2]\n",
    "\n",
    "y_enc = one_hot_encoding(index_array = y, num_classes= 4)\n",
    "\n",
    "print(f\"One hot encoding matrix is \\n{y_enc}\")\n",
    "print(hot_encode.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20564ce7-242d-4283-8293-b961540cc9ac",
   "metadata": {},
   "source": [
    "## Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e56ab0ec-dbbe-488e-b54c-c669a268d338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3000, -0.5000, -0.5000],\n",
       "        [-0.4000, -0.1000, -0.5000],\n",
       "        [-0.3000, -0.9400, -0.5000],\n",
       "        [-0.9900, -0.8800, -0.5000]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = torch.tensor( [[-0.3,  -0.5, -0.5],\n",
    "                   [-0.4,  -0.1, -0.5],\n",
    "                   [-0.3,  -0.94, -0.5],\n",
    "                   [-0.99, -0.88, -0.5]])\n",
    "\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a59b7c62-fca0-4eda-83fb-2a1a11d066f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax:\n",
      " tensor([[0.3792, 0.3104, 0.3104],\n",
      "        [0.3072, 0.4147, 0.2780],\n",
      "        [0.4263, 0.2248, 0.3490],\n",
      "        [0.2668, 0.2978, 0.4354]])\n"
     ]
    }
   ],
   "source": [
    "#Next, we convert them to \"probabilities\" via softmax: \n",
    "def softmax(z):\n",
    "    return (torch.exp(z.t()) / torch.sum(torch.exp(z), dim=1)).t()\n",
    "\n",
    "smax = softmax(Z)\n",
    "print('softmax:\\n', smax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edb97be0-6a53-4d6f-9b11-dfa3be7d75c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class labels:  tensor([0, 1, 0, 2])\n",
      "true class labels:  tensor([0, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# The probabilties can then be converted back to class labels based on the largest probability\n",
    "# in each row:\n",
    "\n",
    "def to_classlabel(z):\n",
    "    return torch.argmax(z, dim= 1)\n",
    "\n",
    "print('predicted class labels: ', to_classlabel(smax))\n",
    "print('true class labels: ', to_classlabel(y_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6cbd2-ed91-4fe0-881c-40700e340e52",
   "metadata": {},
   "source": [
    "### GPU number system\n",
    "GPU architectures are optimized for 32-bit computations, and using this data type can significantly speed up model training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53b81229-7f38-478a-8afc-22eda55113f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam_vec1 = torch.tensor([0,1.0,2.0,4.0])\n",
    "sam_vec1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fac582f-c322-47a0-84d6-eb72b5062147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam_vec2 = sam_vec1.to(torch.float64)\n",
    "sam_vec2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd215b-3e1d-41a0-a19b-17a626cc74e2",
   "metadata": {},
   "source": [
    "## Reshaping operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4cd74c1-5146-412a-bbd2-d51bc66d0f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "tensor2d = torch.tensor([[1, 2, 3], \n",
    "                         [4, 5, 6]])\n",
    "print(tensor2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a963f76d-8f20-4fec-b92a-f88212590f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor2d_re6 = tensor2d.view(6,1)\n",
    "tensor2d_re6 = tensor2d.view(-1,1)\n",
    "tensor2d_re6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f14c5dca-4d35-43c2-97ac-525b4f119c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d_re3 = tensor2d.view(3,2)\n",
    "tensor2d_re3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d9006-f90b-438a-a8da-a9690fb31ae0",
   "metadata": {},
   "source": [
    "## Computation graphs\n",
    "A computational graph is a directed graph that allows us to express and visualize mathematical expressions. In the context of deep learning, a computation graph lays out the sequence of calculations needed to compute the output of a neural network—we will need this to compute the required gradients for backpropagation, the main training algorithm for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61ef510c-74d3-404f-8e42-90b0406d4ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0852)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F #1\n",
    "\n",
    "y = torch.tensor([1.0])         #2\n",
    "x1 = torch.tensor([1.1])        #3\n",
    "w1 = torch.tensor([2.2])        #4\n",
    "b = torch.tensor([0.0])         #5\n",
    "z = x1 * w1 + b                 #6\n",
    "a = torch.sigmoid(z)            #7. Make everything within 0 and 1. Good for Logistic Regression\n",
    "loss = F.binary_cross_entropy(a, y)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b8dc004-803c-46d1-946b-63ff12fb03a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of z: tensor([2.4200]) \n",
      "Value of a: tensor([0.9183])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Value of z: {z} \\nValue of a: {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0bc15-7dde-4ef1-8cb6-984ce98f99d8",
   "metadata": {},
   "source": [
    "## Computing gradients via autograd\n",
    "If we carry out computations in PyTorch, it will build a **computational graph** internally by default if one of its terminal nodes has the **requires_grad** attribute set to True.\n",
    "\n",
    "#1 By default, PyTorch destroys the computation graph after calculating the gradients to free memory. However, since we will reuse this computation graph shortly, we set **retain_graph=True** so that it stays in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cee51068-f3cb-4335-8560-c8c8283e2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "\n",
    "y = torch.tensor([1.0])\n",
    "x1 = torch.tensor([1.1])\n",
    "w1 = torch.tensor([2.2], requires_grad=True)\n",
    "b = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "z = x1 * w1 + b \n",
    "a = torch.sigmoid(z)\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y)\n",
    "\n",
    "grad_L_w1 = grad(loss, w1, retain_graph=True)   #1\n",
    "grad_L_b = grad(loss, b, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0a8fa6a-0e09-43f0-b4d4-766f95516f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.0898]),)\n",
      "(tensor([-0.0817]),)\n"
     ]
    }
   ],
   "source": [
    "print(grad_L_w1)\n",
    "print(grad_L_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99af138d-ab5a-4b29-8708-05f77a58fec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0898])\n",
      "tensor([-0.0817])\n"
     ]
    }
   ],
   "source": [
    "# Pytorch autmatic loss calculator\n",
    "loss.backward()\n",
    "print(w1.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fc26d-587e-43d8-9b03-0e5be802a860",
   "metadata": {},
   "source": [
    "## Implementing multilayer neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07ad08f0-93df-4355-8ca1-955d0119e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "# Simple neural network model\n",
    "class simpleNNmodel(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            # 1st hidden layer with non-linear activation\n",
    "            torch.nn.Linear(num_inputs, 30),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # 2nd hidden layer with non-linear activation\n",
    "            torch.nn.Linear(30, 10),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # ouput layers\n",
    "            torch.nn.Linear(10, num_outputs)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e44cb3b-0745-4fa9-8b76-776eeb99efe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleNNmodel(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = simpleNNmodel(num_inputs = 20, num_outputs=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c47d88c8-c917-4c19-9b8a-6d5630d02800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "951\n"
     ]
    }
   ],
   "source": [
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1f0db6f-8b5e-45ec-9c20-a9d37fb8b025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e8d1cac-3796-4f20-b147-ed2e9b55eaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 20])\n",
      "torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight.shape)\n",
    "print(model.layers[0].bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb9edabe-61c8-4339-af1a-fc9b3ef718c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3963,  0.1176,  0.0802]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Use the model\n",
    "torch.manual_seed(123)\n",
    "X = torch.randn((1, 50))\n",
    "\n",
    "model = simpleNNmodel(num_inputs = 50, num_outputs=3)\n",
    "\n",
    "out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8833dd0c-4970-439d-8ca1-003f89935387",
   "metadata": {},
   "source": [
    "**Addmm** stands for matrix multiplication (mm) followed by an addition (Add).\n",
    "If we use model for prediction, no need to create computational graph in the background to conduct backpropagation. Therefore, **no_grad()** can be used for effective memory use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8edbc790-2b0e-4ee2-84de-76f56d020849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2335, 0.3904, 0.3761]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = torch.softmax(model(X), dim=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d528a6-8035-4d14-b08c-6cd203e2f4c3",
   "metadata": {},
   "source": [
    "##  Setting up efficient data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b032cbf0-dfbf-49ea-aac0-01414ff8b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('the-verdict.txt', 'r') as f:\n",
    "    texts = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abde6039-24e6-426b-85c3-6a62c1d97e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\n",
      "\n",
      "\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it'\n"
     ]
    }
   ],
   "source": [
    "print(texts[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db270e84-7696-46e0-b9d6-2c6069a855cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20479"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afaaec18-643e-4c40-8c4e-253a1bb1701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba0fa38c-1410-4009-9ee5-22f22ff35be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138, 257, 7026, 15632, 438, 2016, 257, 922, 5891, 1576, 438]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode(texts)\n",
    "print(tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a343b7b-edde-4779-aebf-7c4f593be54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokens[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b136eb-5fde-4e02-961a-2d7069c27886",
   "metadata": {},
   "source": [
    "### Dataset for testing codes from book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0abfac11-5dab-4305-97f3-cce2dda99c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure GPU or CPU intigration based on vaiability\n",
    "#-----------------------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "X_train = torch.tensor([\n",
    "    [-1.2, 3.1],\n",
    "    [-0.9, 2.9],\n",
    "    [-0.5, 2.6],\n",
    "    [2.3, -1.1],\n",
    "    [2.7, -1.5]\n",
    "])\n",
    "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
    "\n",
    "X_test = torch.tensor([\n",
    "    [-0.8, 2.8],\n",
    "    [2.6, -1.6],\n",
    "])\n",
    "y_test = torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "988d1db6-59bf-4c85-924a-9460a27393c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.features = X\n",
    "        self.labels = y\n",
    "\n",
    "    def __getitem__(self, index):        #1\n",
    "        one_x = self.features[index]     #1\n",
    "        one_y = self.labels[index]       #1\n",
    "        return one_x, one_y              #1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]      #2\n",
    "\n",
    "train_ds = ToyDataset(X_train, y_train)\n",
    "test_ds = ToyDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52007cf3-9c8d-48a8-90aa-6f7e14c23471",
   "metadata": {},
   "source": [
    "the __getitem__ method, we define instructions for returning exactly one item from the dataset via an index. This refers to the features and the class label corresponding to a single training example or test instance. (The data loader will provide this index, which we will cover shortly.)\n",
    "\n",
    "Finally, the __len__ method contains instructions for retrieving the length of the dataset. Here, we use the .shape attribute of a tensor to return the number of rows in the feature array. In the case of the training dataset, we have five rows, which we can double-check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98beb9a5-ee26-46e2-a728-82df65554afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-1.2000,  3.1000]), tensor(0))\n",
      "(tensor([-0.9000,  2.9000]), tensor(0))\n",
      "(tensor([-0.5000,  2.6000]), tensor(0))\n",
      "(tensor([ 2.3000, -1.1000]), tensor(1))\n",
      "(tensor([ 2.7000, -1.5000]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_ds)):\n",
    "    print(train_ds[i])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd4985ba-221e-4af2-9b62-46d723a0624b",
   "metadata": {},
   "source": [
    "DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,\n",
    "           batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "           pin_memory=False, drop_last=False, timeout=0,\n",
    "           worker_init_fn=None, *, prefetch_factor=2,\n",
    "           persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1aa38567-629f-427e-9e6d-64a4775ad29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      " tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "Batch 2:\n",
      " tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 3:\n",
      " tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size = 2, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_ds, batch_size = 2, shuffle=False, num_workers=0)\n",
    "\n",
    "for idx, (x, y)  in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\\n\",x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99f1b534-8b18-458f-9431-f0cc7e634ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      " tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "Batch 2:\n",
      " tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "# Dropping last item of length < batch_size\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size = 2, shuffle=True, num_workers=0, drop_last=True)\n",
    "test_loader = DataLoader(test_ds, batch_size = 2, shuffle=False, num_workers=0, drop_last=True)\n",
    "\n",
    "for idx, (x, y)  in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\\n\",x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2a3477-97fb-4325-bed8-78c34017f2fa",
   "metadata": {},
   "source": [
    "### Training the Neural Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a63a7d31-4749-46c5-83d2-cde164bee771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 batch 1/2 loss: 0.62\n",
      "Epoch 1/3 batch 2/2 loss: 1.29\n",
      "Epoch 2/3 batch 1/2 loss: 0.50\n",
      "Epoch 2/3 batch 2/2 loss: 0.11\n",
      "Epoch 3/3 batch 1/2 loss: 0.25\n",
      "Epoch 3/3 batch 2/2 loss: 0.01\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = simpleNNmodel(num_inputs =2, num_outputs=2)\n",
    "\n",
    "# Ensure GPU or CPU intigration based on vaiability\n",
    "#-----------------------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "num_epoch = 3\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch, (features, labels) in enumerate(train_loader):\n",
    "        #-----------------------------------------------------------------------------\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        #-----------------------------------------------------------------------------\n",
    "        logits = model(features)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epoch} batch {batch+1}/{len(train_loader)} loss: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bddb82a6-99b4-4675-ae65-940ee8fee0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.5207, -2.6019],\n",
      "        [ 3.1539, -2.2931],\n",
      "        [ 2.6345, -1.8633],\n",
      "        [-0.0796,  1.0342],\n",
      "        [-0.0980,  1.2070]], device='cuda:0')\n",
      "tensor([[0.9978, 0.0022],\n",
      "        [0.9957, 0.0043],\n",
      "        [0.9890, 0.0110],\n",
      "        [0.2472, 0.7528],\n",
      "        [0.2133, 0.7867]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_train = X_train.to(device)  # Ensure input is on the same device\n",
    "    outputs = model(X_train)\n",
    "print(outputs)\n",
    "\n",
    "probas = torch.softmax(outputs, dim=1)\n",
    "print(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6da8927d-f608-4f46-a733-b12f4de90b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = torch.argmax(probas, dim=1)\n",
    "print(predictions)\n",
    "\n",
    "# comparing prediction with true values\n",
    "predictions == y_train.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b852ab6d-2b15-47c8-82e8-85e551cacaa7",
   "metadata": {},
   "source": [
    "### Computing Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340fd2b5-8f85-481d-8991-9b039c4e8076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a217e5c-810c-440c-bc35-6d77a132c3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d62f7017-4215-4310-81ff-4dca2681e2f4",
   "metadata": {},
   "source": [
    "## Working with Multiple GPUs\n",
    "\n",
    "DDP does not function properly within interactive Python environments like Jupyter notebooks, which don’t handle multiprocessing in the same way a standalone Python script does. Therefore, the following code should be executed as a script, not within a notebook interface like Jupyter. DDP needs to spawn multiple processes, and each process should have its own Python interpreter instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68411e9-c71e-42b0-b3b4-97381d0e839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Mac GPU\n",
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "# For Nvidia GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8369ae1-b53d-433b-9669-4c7e9a41cfdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766fb41-c660-4ae7-92f2-c7c9be64e6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c16940a-6d2d-4d29-9d6a-2e0d6929c75d",
   "metadata": {},
   "source": [
    "## Creating dataset and dataloader for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57e823-3192-4398-a812-1ae627c9ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c605b438-c06a-4e54-982b-30bf8c21c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTdataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        tokens = tokenizer.encode(texts)\n",
    "        \n",
    "        for i in range(0, len(tokens)-max_length, stride):\n",
    "            input_chunk = tokens[i : i+max_length]\n",
    "            target_chunk = tokens[i+1 : i+max_length+1]\n",
    "        \n",
    "            input_tensors = torch.tensor(input_chunk)\n",
    "            self.input_ids.append(input_tensors)\n",
    "        \n",
    "            target_tensors = torch.tensor(target_chunk)\n",
    "            self.target_ids.append(target_tensors)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids[index], self.target_ids[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55a5e09c-b529-4aec-bc2d-22e07caf3f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "****************************************************************************************************\n",
      "(tensor([  40,  367, 2885, 1464]), tensor([ 367, 2885, 1464, 1807]))\n",
      "(tensor([1807, 3619,  402,  271]), tensor([ 3619,   402,   271, 10899]))\n",
      "(tensor([10899,  2138,   257,  7026]), tensor([ 2138,   257,  7026, 15632]))\n",
      "(tensor([15632,   438,  2016,   257]), tensor([ 438, 2016,  257,  922]))\n",
      "(tensor([ 922, 5891, 1576,  438]), tensor([5891, 1576,  438,  568]))\n",
      "(tensor([568, 340, 373, 645]), tensor([340, 373, 645, 308]))\n"
     ]
    }
   ],
   "source": [
    "dataset = GPTdataset(texts[:100], tokenizer=tokenizer,max_length=4, stride=4)\n",
    "\n",
    "print(len(dataset))\n",
    "print(\"*\"*100)\n",
    "for i in range(len(dataset)):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16a21143-4986-4248-be4e-410191cfac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPTdataloader(texts, max_length=8, stride=8,\n",
    "                 batch_size = 2, shuffle=True, num_workers=0, drop_last=True):\n",
    "    \n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTdataset(texts, tokenizer=tokenizer, max_length=max_length, stride=stride)\n",
    "    dataloader = DataLoader(\n",
    "                            dataset = dataset,\n",
    "                            batch_size = batch_size,\n",
    "                            shuffle =shuffle,\n",
    "                            num_workers =num_workers,\n",
    "                            drop_last =drop_last\n",
    "                            )\n",
    "    return dataloader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d835bb3-bb4f-45dd-a8d0-0d8e50ab5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = GPTdataloader(texts[:100], max_length=8, stride=8,\n",
    "              batch_size = 2, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "01c02003-e294-4142-881d-a3709f280119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[10899,  2138,   257,  7026, 15632,   438,  2016,   257],\n",
      "        [   40,   367,  2885,  1464,  1807,  3619,   402,   271]]) \n",
      " target: tensor([[ 2138,   257,  7026, 15632,   438,  2016,   257,   922],\n",
      "        [  367,  2885,  1464,  1807,  3619,   402,   271, 10899]])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(dataloader)    \n",
    "first_batch = next(data_iter)\n",
    "print('input:',first_batch[0],\"\\n\",'target:', first_batch[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017557e-8cfd-4a9b-a743-5d785e327204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1ee25-60ed-4305-817a-fdaa38005c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
